metadata:
[]

models:
id: 1, filename: /storage/cmarnold/SecureLLM/trained_models/trained_model_1.pt, info_json:{"epoch": 1, "save_date": "2024-05-01_18:35:06", "experiment": "0", "sub_experiment": "0", "my_uuid": "6b5926a0-b519-4474-9c57-fa092d16a7e4", "sample_limit": null, "model_args": {"name": "llama-2-7b", "max_seq_len": "1024", "max_batch_size": "32", "type": "lora", "lora_r": "8", "lora_alpha": "32", "lora_dropout": "0.1"}, "dataset_args": {"train_str": "schemapseudo_1:10,schemapseudo_2:10,schemapseudo_3:10", "val_str": "schemapseudo_1_val:10,schemapseudo_2_val:10,schemapseudo_3_val:10", "max_inp_matrix_size": "800"}, "train_args": {"epochs": "3", "lr": "2e-4", "weight_decay": "0.002"}, "seed": 2, "full_command": "train.py --dataset_args train_str=schemapseudo_1:10,schemapseudo_2:10,schemapseudo_3:10 val_str=schemapseudo_1_val:10,schemapseudo_2_val:10,schemapseudo_3_val:10 max_inp_matrix_size=800 --model_args name=llama-2-7b max_seq_len=1024 max_batch_size=32 type=lora lora_r=8 lora_alpha=32 lora_dropout=0.1 --train_args epochs=3 lr=2e-4 weight_decay=0.002 --experiment 0.0 --world_size 1 --seed 2 --device cuda:3", "metada": {"val": {"schemapseudo_1_val": {"v": [0, 10, 10], "to_print": "0.0% (10)"}, "schemapseudo_2_val": {"v": [0, 10, 10], "to_print": "0.0% (10)"}, "schemapseudo_3_val": {"v": [0, 10, 10], "to_print": "0.0% (10)"}, "no_acc": {"count": 0}, "unk": {}}}}
id: 2, filename: /storage/cmarnold/SecureLLM/trained_models/trained_model_2.pt, info_json:{"epoch": 2, "save_date": "2024-05-01_18:39:00", "experiment": "0", "sub_experiment": "0", "my_uuid": "6b5926a0-b519-4474-9c57-fa092d16a7e4", "sample_limit": null, "model_args": {"name": "llama-2-7b", "max_seq_len": "1024", "max_batch_size": "32", "type": "lora", "lora_r": "8", "lora_alpha": "32", "lora_dropout": "0.1"}, "dataset_args": {"train_str": "schemapseudo_1:10,schemapseudo_2:10,schemapseudo_3:10", "val_str": "schemapseudo_1_val:10,schemapseudo_2_val:10,schemapseudo_3_val:10", "max_inp_matrix_size": "800"}, "train_args": {"epochs": "3", "lr": "2e-4", "weight_decay": "0.002"}, "seed": 2, "full_command": "train.py --dataset_args train_str=schemapseudo_1:10,schemapseudo_2:10,schemapseudo_3:10 val_str=schemapseudo_1_val:10,schemapseudo_2_val:10,schemapseudo_3_val:10 max_inp_matrix_size=800 --model_args name=llama-2-7b max_seq_len=1024 max_batch_size=32 type=lora lora_r=8 lora_alpha=32 lora_dropout=0.1 --train_args epochs=3 lr=2e-4 weight_decay=0.002 --experiment 0.0 --world_size 1 --seed 2 --device cuda:3", "metada": {"val": {"schemapseudo_1_val": {"v": [0, 10, 10], "to_print": "0.0% (10)"}, "schemapseudo_2_val": {"v": [0, 10, 10], "to_print": "0.0% (10)"}, "schemapseudo_3_val": {"v": [0, 10, 10], "to_print": "0.0% (10)"}, "no_acc": {"count": 0}, "unk": {}}}}
id: 3, filename: /storage/cmarnold/SecureLLM/trained_models/trained_model_3.pt, info_json:{"epoch": 3, "save_date": "2024-05-01_18:41:29", "experiment": "0", "sub_experiment": "0", "my_uuid": "6b5926a0-b519-4474-9c57-fa092d16a7e4", "sample_limit": null, "model_args": {"name": "llama-2-7b", "max_seq_len": "1024", "max_batch_size": "32", "type": "lora", "lora_r": "8", "lora_alpha": "32", "lora_dropout": "0.1"}, "dataset_args": {"train_str": "schemapseudo_1:10,schemapseudo_2:10,schemapseudo_3:10", "val_str": "schemapseudo_1_val:10,schemapseudo_2_val:10,schemapseudo_3_val:10", "max_inp_matrix_size": "800"}, "train_args": {"epochs": "3", "lr": "2e-4", "weight_decay": "0.002"}, "seed": 2, "full_command": "train.py --dataset_args train_str=schemapseudo_1:10,schemapseudo_2:10,schemapseudo_3:10 val_str=schemapseudo_1_val:10,schemapseudo_2_val:10,schemapseudo_3_val:10 max_inp_matrix_size=800 --model_args name=llama-2-7b max_seq_len=1024 max_batch_size=32 type=lora lora_r=8 lora_alpha=32 lora_dropout=0.1 --train_args epochs=3 lr=2e-4 weight_decay=0.002 --experiment 0.0 --world_size 1 --seed 2 --device cuda:3", "metada": {"val": {"schemapseudo_1_val": {"v": [0, 10, 10], "to_print": "0.0% (10)"}, "schemapseudo_2_val": {"v": [0, 10, 9], "to_print": "0.0% (9)"}, "schemapseudo_3_val": {"v": [1, 10, 9], "to_print": "10.0% (9)"}, "no_acc": {"count": 0}, "unk": {}}}}
