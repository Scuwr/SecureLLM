# train / val on multiple choice dataset
python train.py \
    --dataset_args \
        train_str="schemapseudo_1:1000,schemapseudo_2:1000,schemapseudo_3:1000" \
        val_str="schemapseudo_1_val:100,schemapseudo_2_val:100,schemapseudo_3_val:100" \
        max_inp_matrix_size=800 \
    --model_args \
        name=llama-2-7b \
        max_seq_len=1024 \
        max_batch_size=32 \
        type=lora \
        lora_r=8 \
        lora_alpha=32 \
        lora_dropout=0.1 \
    --train_args \
        epochs=3 \
        lr=2e-4 \
        weight_decay=0.002 \
    --experiment "0.0" \
    --world_size 1 \
    --seed 2 \
    --device cuda:3

# ---MODELS---
# for lora
        type=lora \
        lora_r=8 \
        lora_alpha=32 \
        lora_dropout=0.1 \

# 70 B
python train.py \
    --dataset_args \
        val_str="schema_2_val:500" \
        max_inp_matrix_size=800 \
    --model_args \
        name=llama-2-7b \
        max_seq_len=1024 \
        max_batch_size=32 \
        type=lora \
        lora_r=8 \
        lora_alpha=32 \
        lora_dropout=0.1 \
        load="/path/to/model.pt" \
    --experiment "0.0" \
    --world_size 8 \
    --device cuda:0 \

# experiments
python experiments.py --device 3 --sample_size 120 --mroot "./trained_models/6NF/" --pseudo --models M1 M2